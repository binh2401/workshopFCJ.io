
---
title: "Graph Neural Networks vá»›i Neptune ML(chÆ°a xong)"
date: 2025-08-05
weight: 6
chapter: false
pre: "<b> 6. </b>"
---
## ğŸ¯ Má»¥c tiÃªu
HÆ°á»›ng dáº«n xuáº¥t dá»¯ liá»‡u tá»« SQL Server sang file CSV vÃ  upload thá»§ cÃ´ng lÃªn Amazon S3 Ä‘á»ƒ sá»­ dá»¥ng trong Amazon Neptune.

---

## ğŸ§± BÆ°á»›c 1: CÃ i Ä‘áº·t thÆ° viá»‡n cáº§n thiáº¿t

### CÃ i Ä‘áº·t báº±ng `pip`:

```bash
pip install pandas pyodbc boto3
```

---

## ğŸ§© BÆ°á»›c 2: Káº¿t ná»‘i SQL Server vÃ  xuáº¥t dá»¯ liá»‡u ra thÆ° má»¥c `./export`

### ğŸ“ Cáº¥u trÃºc thÆ° má»¥c:
```
project/
â”‚
â”œâ”€â”€ export/         # Chá»©a cÃ¡c file CSV sau khi export
â”œâ”€â”€ data.py         # Script Python Ä‘á»ƒ export
```

### ğŸ”¢ Code `data.py`:

```python
import os
import pandas as pd
from sqlalchemy import create_engine

# Chuá»—i káº¿t ná»‘i
server = '(localdb)\\MSSQLLocalDB'
database = 'boookstore'
conn_str = f'mssql+pyodbc://@{server}/{database}?driver=ODBC+Driver+17+for+SQL+Server'

# Táº¡o engine káº¿t ná»‘i
engine = create_engine(conn_str)

# Danh sÃ¡ch báº£ng cáº§n export
tables = ['dbo.Categories', 'dbo.Products', 'dbo.Orders']

# ThÆ° má»¥c lÆ°u file CSV
output_folder = './export'
os.makedirs(output_folder, exist_ok=True)

# Xuáº¥t dá»¯ liá»‡u tá»«ng báº£ng
for table in tables:
    print(f"ğŸ“Œ Äang xá»­ lÃ½ báº£ng: {table}")
    df = pd.read_sql(f"SELECT * FROM {table}", engine)
    table_name = table.split('.')[-1]
    df.to_csv(f'{output_folder}/{table_name}.csv', index=False)
    print(f"âœ… ÄÃ£ lÆ°u: {table_name}.csv")
```

---

## â˜ï¸ BÆ°á»›c 3: Upload thá»§ cÃ´ng lÃªn Amazon S3

1. VÃ o [AWS S3 Console](https://s3.console.aws.amazon.com/s3)
2. Táº¡o má»™t bucket (náº¿u chÆ°a cÃ³)
3. VÃ o bucket Ä‘Ã³ â†’ "Upload" â†’ Chá»n cÃ¡c file `.csv` trong thÆ° má»¥c `./export`
4. Sau khi upload, copy Ä‘Æ°á»ng dáº«n S3 URI cá»§a cÃ¡c file (vÃ­ dá»¥: `s3://your-bucket-name/Categories.csv`)
![FWD](/images/6.clean/s31.png)
![FWD](/images/6.clean/s32.png)
---

